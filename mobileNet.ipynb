{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1259264,"sourceType":"datasetVersion","datasetId":724551}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport os\nimport glob\nimport shutil\n\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport tensorflow as tf\n\n# Import packages for data handling\nimport h5py\nfrom PIL import Image\nfrom skimage.io import imread\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom mlxtend.plotting import plot_confusion_matrix\n\n# Import deep learning package (tensorflow)\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications import mobilenet_v2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Concatenate\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\nfrom tensorflow.keras.utils import to_categorical\n\ncolor = sns.color_palette()\n%matplotlib inline\n\n# Set seed nunmber to all packages\nseed_number = 24\nnp.random.seed(seed_number)\ntf.random.set_seed(seed_number)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:56:48.911183Z","iopub.execute_input":"2025-04-14T10:56:48.911378Z","iopub.status.idle":"2025-04-14T10:57:07.028554Z","shell.execute_reply.started":"2025-04-14T10:56:48.911332Z","shell.execute_reply":"2025-04-14T10:57:07.027757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuring directories\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nroot = \"../input/lcc-fasd\"\ninput_dir = os.path.join(root,\"LCC_FASD\")\ntrain_dir = os.path.join(input_dir, 'LCC_FASD_training')\nval_dir = os.path.join(input_dir, 'LCC_FASD_development')\ntest_dir = os.path.join(input_dir, 'LCC_FASD_evaluation')\n\ndataset_dir = [dir for dir in sorted(os.listdir(input_dir)) if os.path.isdir(os.path.join(input_dir, dir))]\nlabel_name = [subdir for subdir in sorted(os.listdir(train_dir)) if os.path.isdir(os.path.join(train_dir, subdir))]\n\n# Printing the directory informations\nprint(f\"Main directories\\t: {os.listdir(root)}\")\nprint(f\"Dataset sub-directories\\t: {dataset_dir}\")\nprint(f\"Train set directory\\t: {label_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:57:07.032332Z","iopub.execute_input":"2025-04-14T10:57:07.032591Z","iopub.status.idle":"2025-04-14T10:57:07.075793Z","shell.execute_reply.started":"2025-04-14T10:57:07.032573Z","shell.execute_reply":"2025-04-14T10:57:07.075254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dir_dict = {'train': train_dir, 'val': val_dir, 'test': test_dir}\ncase_count, img_disp, set_length  = {}, {}, {}\n\nfor key, val in dir_dict.items():\n    case_count[key] = {}\n    img_disp[key] = {}\n    set_count = 0\n    \n    for label in label_name:\n        label_list = list(sorted(glob.glob(os.path.join(val, label, \"*.png\"))))\n        if len(label_list) == 0:\n          continue\n\n        case_count[key][label] = len(label_list)\n        set_count += len(label_list)\n        \n        select_img_id = np.random.randint(len(label_list)-1)\n        # print(select_img_id)\n        img_disp[key][label] = label_list[select_img_id]\n        \n    set_length[key] = set_count\n\ncase_count_df = pd.DataFrame(case_count)\nimg_disp_df = pd.DataFrame(img_disp)\nprint(f\"Dataset summary:\\n\\n{case_count_df}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:57:14.359702Z","iopub.execute_input":"2025-04-14T10:57:14.360166Z","iopub.status.idle":"2025-04-14T10:57:16.002139Z","shell.execute_reply.started":"2025-04-14T10:57:14.360144Z","shell.execute_reply":"2025-04-14T10:57:16.001383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing some of the data set\nnum_classes = len(label_name)\nnum_dataset = 0\nfor key, val in set_length.items():\n  num_dataset += 1 if val > 0 else 0\n\nf, ax = plt.subplots(num_classes, num_dataset, figsize=(num_dataset*10, 18))\n\nfor k in range(num_classes*num_dataset):\n    j, i = k//num_dataset, k%num_dataset  # Image indexing\n    \n    img = imread(img_disp_df.iloc[j, i])\n    ax[j, i].imshow(img, cmap='gray')\n    ax[j, i].set_title(f\"{img_disp_df.columns[i].upper()}: {img_disp_df.index[j].capitalize()}\", fontsize=32)\n    ax[j, i].axis('off')\n    ax[j, i].set_aspect('auto')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:57:33.270084Z","iopub.execute_input":"2025-04-14T10:57:33.270654Z","iopub.status.idle":"2025-04-14T10:57:35.33617Z","shell.execute_reply.started":"2025-04-14T10:57:33.270629Z","shell.execute_reply":"2025-04-14T10:57:35.335014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate data generator for training procedure\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   rotation_range = 20,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.15,\n                                   zoom_range = 0.15,\n                                   horizontal_flip = True,\n                                   fill_mode=\"nearest\")\n\nval_datagen = ImageDataGenerator(rescale = 1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255) if set_length[\"test\"] > 0 else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:57:54.318528Z","iopub.execute_input":"2025-04-14T10:57:54.319056Z","iopub.status.idle":"2025-04-14T10:57:54.323108Z","shell.execute_reply.started":"2025-04-14T10:57:54.319032Z","shell.execute_reply":"2025-04-14T10:57:54.322549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define dataset properties\ntrain_batch_size = 32\nval_batch_size = 32\nimg_width = 224\nimg_height = 224\n\n# Generate dataset for train, val and test\ntrain_gen = train_datagen.flow_from_directory(train_dir,\n                                              batch_size = train_batch_size,\n                                              class_mode = 'binary',\n                                              target_size = (img_width, img_height),\n                                              seed = seed_number)\n\nval_gen = val_datagen.flow_from_directory(val_dir,\n                                          batch_size = val_batch_size,\n                                          class_mode = 'binary',\n                                          target_size = (img_width, img_height),\n                                          seed = seed_number)\n\nif test_datagen is not None:\n  test_gen = test_datagen.flow_from_directory(test_dir,\n                                              batch_size = 1,\n                                              class_mode = 'binary',\n                                              target_size = (img_width, img_height),\n                                              seed = seed_number,\n                                              shuffle=False)\nelse:\n  test_gen = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:58:11.370275Z","iopub.execute_input":"2025-04-14T10:58:11.37059Z","iopub.status.idle":"2025-04-14T10:58:46.068081Z","shell.execute_reply.started":"2025-04-14T10:58:11.370569Z","shell.execute_reply":"2025-04-14T10:58:46.06755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Displaying the dataset generator information\nprint(f'Train set batch shape\\t: {next(train_gen)[0].shape}')\nprint(f'Val set batch shape\\t: {next(val_gen)[0].shape}')\nprint(f'Test set batch shape\\t: {next(test_gen)[0].shape}') if test_gen is not None else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:58:46.069107Z","iopub.execute_input":"2025-04-14T10:58:46.069383Z","iopub.status.idle":"2025-04-14T10:58:47.516917Z","shell.execute_reply.started":"2025-04-14T10:58:46.06936Z","shell.execute_reply":"2025-04-14T10:58:47.516297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Don't forget to turn on the Internet to download the respective pre-trained weights!\npretrain_net = mobilenet_v2.MobileNetV2(input_shape = (img_width, img_height, 3),\n                                        include_top = False,\n                                        weights = 'imagenet')\n\n# load_param_path = '../input/mobilenet_v2/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'  # Offline alternative\n# pretrain_net.load_weights(load_param_path)  # Manually load the weights from the input directory\n\n# ------ Freezing layer(s) up to a specific layer ------\nfreeze_before = None  #\"block_16_expand\"  # use None to train, use \"all\" to freeze all the layers\n\nif freeze_before:\n    for layer in pretrain_net.layers:\n        if layer.name == freeze_before:\n            break\n        else:\n            layer.trainable = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:59:03.219504Z","iopub.execute_input":"2025-04-14T10:59:03.219748Z","iopub.status.idle":"2025-04-14T10:59:06.803363Z","shell.execute_reply.started":"2025-04-14T10:59:03.21973Z","shell.execute_reply":"2025-04-14T10:59:06.802768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Adding extra layer for our problem\nx = pretrain_net.output\nx = Conv2D(32, (3, 3), activation='relu')(x)\nx = Dropout(rate=0.2, name='extra_dropout1')(x)\nx = GlobalAveragePooling2D()(x)\n# x = Dense(units=128, activation='relu', name='extra_fc1')(x)\n# x = Dropout(rate=0.2, name='extra_dropout1')(x)\nx = Dense(1, activation='sigmoid', name='classifier')(x)\n\nmodel = Model(inputs=pretrain_net.input, outputs=x, name='mobilenetv2_spoof')\nprint(model.summary())\n\n# Notice: Unhide the OUTPUT!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:59:39.277429Z","iopub.execute_input":"2025-04-14T10:59:39.277957Z","iopub.status.idle":"2025-04-14T10:59:39.428615Z","shell.execute_reply.started":"2025-04-14T10:59:39.277936Z","shell.execute_reply":"2025-04-14T10:59:39.42789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_id = \"lcc-train04b-weight_all\"  # ID of the training procedure\nnum_epochs = 15  # Set the number of epochs to train\nlearning_rate = 5e-5  # Set the learning rate to use\n\nprint(f\"Training config of '{train_id}'...\")\nprint(f\"Number of epoch\\t: {num_epochs}\")\nprint(f\"Initial LR\\t: {learning_rate}\")\n\nmodel.compile(optimizer = Adam(learning_rate=learning_rate),\n              loss = 'binary_crossentropy',\n              metrics = ['acc'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:02:53.067372Z","iopub.execute_input":"2025-04-14T11:02:53.067659Z","iopub.status.idle":"2025-04-14T11:02:53.077858Z","shell.execute_reply.started":"2025-04-14T11:02:53.067639Z","shell.execute_reply":"2025-04-14T11:02:53.077141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate learning rate scheduler with Plateau method\nplateau_scheduler = ReduceLROnPlateau(factor=0.2, patience=3, verbose=1, \n                                      min_delta= 0.005, min_lr=5e-7)\n\n# Displaying tensorboard\n#%tensorboard --logdir log_dir\n\n# Define class weight\ntrain_length = len(train_gen.classes)\nweight0 = train_length / case_count_df['train'][label_name[0]] * (1 / len(label_name))\nweight1 = train_length / case_count_df['train'][label_name[1]] * (1 / len(label_name))\nclass_weight = {0: weight0, 1: weight1}\n\nprint(f\"Class weight\\t: {class_weight}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:03:44.976164Z","iopub.execute_input":"2025-04-14T11:03:44.976733Z","iopub.status.idle":"2025-04-14T11:03:44.983742Z","shell.execute_reply.started":"2025-04-14T11:03:44.976711Z","shell.execute_reply":"2025-04-14T11:03:44.982974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nhistory = model.fit(train_gen,\n                    epochs = num_epochs,\n                    steps_per_epoch = set_length['train'] // train_batch_size,\n                    validation_data = val_gen,\n                    validation_steps = 1,\n                    callbacks = [\n                                 plateau_scheduler],\n                    class_weight=class_weight)\n\nhistory_df = pd.DataFrame.from_dict(history.history)\nhistory_df.to_csv(os.path.join(save_dir, \"history.csv\"), index=False)\n\n# Notice: Unhide the OUTPUT!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:04:02.6648Z","iopub.execute_input":"2025-04-14T11:04:02.665363Z","iopub.status.idle":"2025-04-14T11:32:26.128152Z","shell.execute_reply.started":"2025-04-14T11:04:02.665326Z","shell.execute_reply":"2025-04-14T11:32:26.127387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"mobilenet_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:33:18.444782Z","iopub.execute_input":"2025-04-14T11:33:18.445079Z","iopub.status.idle":"2025-04-14T11:33:18.935963Z","shell.execute_reply.started":"2025-04-14T11:33:18.445058Z","shell.execute_reply":"2025-04-14T11:33:18.935386Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(\"mobilenet_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:33:30.779127Z","iopub.execute_input":"2025-04-14T11:33:30.77942Z","iopub.status.idle":"2025-04-14T11:33:30.784508Z","shell.execute_reply.started":"2025-04-14T11:33:30.779401Z","shell.execute_reply":"2025-04-14T11:33:30.783889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test set accuracy and loss\ntest_scores = model.evaluate(test_gen, steps=set_length['test'])\nprint(\"Test results Accuracy: {0:.2f}% and Loss: {0:.2f}\".format(test_scores[1]*100, test_scores[0]))\n\n# Calculate prediction\nthreshold = 0.5  # Define the sigmoid threshold for True or False\ny_pred_value = np.squeeze(model.predict(test_gen, steps=set_length['test'], verbose=1))\n\ny_pred = np.zeros(y_pred_value.shape).astype(np.int32)  # Sigmoid\ny_pred[y_pred_value > threshold] = 1\n\n# y_pred = np.argmax(y_pred_value, axis=-1).astype(np.int32)  # Softmax\n\ny_true = test_gen.classes\n\n# Sanity check on the y_pred and y_true value\nprint(f\"Label\\t\\t: {y_true[:10]}\")\nprint(f\"Prediction\\t: {y_pred[:10]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:34:51.616717Z","iopub.execute_input":"2025-04-14T11:34:51.617227Z","iopub.status.idle":"2025-04-14T11:39:54.602012Z","shell.execute_reply.started":"2025-04-14T11:34:51.617203Z","shell.execute_reply":"2025-04-14T11:39:54.601116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion matrix result\nconfusion_matrix_result = confusion_matrix(y_true, y_pred)\nplot_confusion_matrix(confusion_matrix_result,\n                      figsize=(12,8),\n                      hide_ticks=True,\n                      cmap=plt.cm.jet)\nplt.title(\"Face Spoofing Detection\")\nplt.xticks(range(2), ['Real', 'Spoof'], fontsize=16)\nplt.yticks(range(2), ['Real', 'Spoof'], fontsize=16)\nplt.show()\n\n# Precision and Recall metrics\ntn, fp, fn, tp = confusion_matrix_result.ravel()\nprecision = tp / (tp+fp)\nrecall = tp / (tp+fn)\nf1_score = 2 * precision * recall / (precision+recall)\n\nprint(\"Report Summary:\")\nprint(\"Precision\\t: {:.2f}%\".format(precision*100))\nprint(\"Recall\\t\\t: {:.2f}%\".format(recall*100))\nprint(\"F1 Score\\t: {:.2f}%\".format(f1_score*100))\n\nprint(\"\\nNotes: \")\nprint(\"True labels\\t: Spoof\")\nprint(\"False labels\\t: Real\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:42:09.147697Z","iopub.execute_input":"2025-04-14T11:42:09.147975Z","iopub.status.idle":"2025-04-14T11:42:09.293056Z","shell.execute_reply.started":"2025-04-14T11:42:09.147956Z","shell.execute_reply":"2025-04-14T11:42:09.29221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}